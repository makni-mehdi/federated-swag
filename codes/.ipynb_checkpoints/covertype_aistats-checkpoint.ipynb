{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "suffering-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim  as optim\n",
    "from sklearn.datasets import fetch_covtype\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "three-corner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7], dtype=int32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = fetch_covtype(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=5000, test_size=10000, random_state=42)\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.fit_transform(y_test)\n",
    "lb.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "native-consultation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ongoing-swaziland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "separated-nicholas",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = torch.tensor(X_train, dtype=torch.float32), torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train, y_test = torch.tensor(y_train, dtype=torch.float32), torch.tensor(y_test, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "noble-latin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 7])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "metropolitan-civilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = y_train.view(y_train.shape[0], lb.classes_.size)\n",
    "# y_test = y_test.view(y_test.shape[0], lb.classes_.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "conditional-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.lin = nn.Linear(in_dim, out_dim)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        self.in_dim = in_dim\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sig(self.lin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "excess-execution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 54])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "rocky-commerce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5000, 7])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(54, 7)\n",
    "model(X_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adjustable-arizona",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([1., 1., 1.,  ..., 1., 1., 1.]),\n",
       "indices=tensor([1, 1, 1,  ..., 6, 0, 1]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(y_train, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "grave-edwards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1,  ..., 6, 0, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, predicted = torch.max(y_train, 1)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "steady-promotion",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = model(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "patent-level",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 2.0248e-37,\n",
       "        1.0000e+00], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "supposed-people",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iters = 1000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "foreign-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "approved-scheme",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch 0, the loss = 62.05888748168945 and accuracy = 0.8172571428571429\n",
      "Current epoch 50, the loss = 41.705406188964844 and accuracy = 0.8418285714285715\n",
      "Current epoch 100, the loss = 41.262855529785156 and accuracy = 0.8543428571428572\n",
      "Current epoch 150, the loss = 41.262855529785156 and accuracy = 0.8543428571428572\n",
      "Current epoch 200, the loss = 41.262855529785156 and accuracy = 0.8543428571428572\n",
      "Current epoch 250, the loss = 41.262855529785156 and accuracy = 0.8543428571428572\n",
      "Current epoch 300, the loss = 41.262855529785156 and accuracy = 0.8543428571428572\n",
      "Current epoch 350, the loss = 41.262855529785156 and accuracy = 0.8543428571428572\n",
      "Current epoch 400, the loss = 41.262855529785156 and accuracy = 0.8543428571428572\n",
      "Current epoch 450, the loss = 41.262855529785156 and accuracy = 0.8543428571428572\n",
      "Current epoch 500, the loss = 41.262855529785156 and accuracy = 0.8543428571428572\n",
      "Current epoch 550, the loss = 41.262855529785156 and accuracy = 0.8543428571428572\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-b9d3530533eb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mpredicted\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# History data for each epoch\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    running_loss = 0\n",
    "#     correct = 0\n",
    "#     tot = 0\n",
    "    y_hat = model(X_train)\n",
    "    loss = criterion(y_hat, y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "#     for i, (x, y) in enumerate(zip(X_train, y_train)):\n",
    "#         optimizer.zero_grad()\n",
    "#         y_hat = model(x)\n",
    "#         loss = criterion(y_hat, y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         print(optimizer.model.grad)\n",
    "    with torch.no_grad():\n",
    "        running_loss += loss.item()\n",
    "        predicted = torch.zeros(y_train.shape)\n",
    "        for i in range(y_hat.shape[0]):\n",
    "            predicted[i, torch.argmax(y_hat[i])] = 1\n",
    "\n",
    "    correct = (predicted == y_train).sum().item()\n",
    "        \n",
    "    train_loss.append(running_loss)\n",
    "    current_accuracy = correct / (y_train.shape[0] * y_train.shape[1])\n",
    "    train_accuracy.append(current_accuracy)\n",
    "    \n",
    "    if epoch % 50 == 0:\n",
    "        print(f\"Current epoch {epoch}, the loss = {running_loss} and accuracy = {current_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "remarkable-interest",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "industrial-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sacred-surge",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "million-accreditation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1590e+03, 2.4000e+01, 1.5000e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [2.8590e+03, 3.7000e+01, 9.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [2.7130e+03, 9.9000e+01, 1.0000e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        ...,\n",
       "        [3.3800e+03, 9.2000e+01, 1.1000e+01,  ..., 1.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [3.0160e+03, 2.3000e+01, 1.4000e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00],\n",
       "        [2.7590e+03, 6.2000e+01, 2.6000e+01,  ..., 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00]])"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-purchase",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sunset-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(y).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ultimate-maryland",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-anger",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    y_hat_test = model(X_test)\n",
    "    loss = criterion(y_hat_test, y_test)\n",
    "    print(f'loss = {loss.item()}')\n",
    "    y_hat_cls = (y_hat_test > 0.5) * 1\n",
    "    accuracy = (y_hat_cls == y_test).sum() / float(y_test.shape[0])\n",
    "    print(f'accuracy = {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interested-leonard",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
