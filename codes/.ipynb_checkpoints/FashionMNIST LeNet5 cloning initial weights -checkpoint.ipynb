{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"FashionMNIST\"\n",
    "model_cfg = models.reducedLeNet5\n",
    "title = model_cfg.__name__ + \"_\" + dataset_name + \"_federated\"\n",
    "pretrained_init = False\n",
    "pretrained_clients = False\n",
    "n_clients = 10\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "torch.backends.cudnn.benchmark = True\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = getattr(torchvision.datasets, dataset_name)\n",
    "\n",
    "batch_size = 256\n",
    "train_dataset = dataset(root='./data', train=True, download=True, transform=ToTensor())\n",
    "test_dataset = dataset(root='./data', train=False, download=True, transform=ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_init = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 2.316861152648926\n",
      "idx: 10, loss: 2.258511543273926\n",
      "idx: 20, loss: 2.0064644813537598\n",
      "idx: 30, loss: 1.7471089363098145\n",
      "idx: 40, loss: 1.2649407386779785\n",
      "idx: 50, loss: 1.292358160018921\n",
      "idx: 60, loss: 1.1248499155044556\n",
      "idx: 70, loss: 1.0096615552902222\n",
      "idx: 80, loss: 0.9585707187652588\n",
      "idx: 90, loss: 0.8181748390197754\n",
      "idx: 100, loss: 0.8411403298377991\n",
      "idx: 110, loss: 0.8066419363021851\n",
      "idx: 120, loss: 0.8923713564872742\n",
      "idx: 130, loss: 0.7631856203079224\n",
      "idx: 140, loss: 0.6940051913261414\n",
      "idx: 150, loss: 0.6815012693405151\n",
      "idx: 160, loss: 0.7601206302642822\n",
      "idx: 170, loss: 0.6156054139137268\n",
      "idx: 180, loss: 0.6486970782279968\n",
      "idx: 190, loss: 0.7186076045036316\n",
      "idx: 200, loss: 0.603090226650238\n",
      "idx: 210, loss: 0.6762053966522217\n",
      "idx: 220, loss: 0.6829679608345032\n",
      "idx: 230, loss: 0.6882979273796082\n",
      "Epoch 0. LR: 0.1. Loss: 0.5833 Accuracy 0.7681\n",
      "idx: 0, loss: 0.6002697944641113\n",
      "idx: 10, loss: 0.6487754583358765\n",
      "idx: 20, loss: 0.6722362637519836\n",
      "idx: 30, loss: 0.5729120373725891\n",
      "idx: 40, loss: 0.7422106862068176\n",
      "idx: 50, loss: 0.46688422560691833\n",
      "idx: 60, loss: 0.5548880100250244\n",
      "idx: 70, loss: 0.6728891730308533\n",
      "idx: 80, loss: 0.6160369515419006\n",
      "idx: 90, loss: 0.5780255794525146\n",
      "idx: 100, loss: 0.5695571303367615\n",
      "idx: 110, loss: 0.6319403648376465\n",
      "idx: 120, loss: 0.6419057250022888\n",
      "idx: 130, loss: 0.5833834409713745\n",
      "idx: 140, loss: 0.5292643904685974\n",
      "idx: 150, loss: 0.5114544034004211\n",
      "idx: 160, loss: 0.637389600276947\n",
      "idx: 170, loss: 0.485744446516037\n",
      "idx: 180, loss: 0.5437026023864746\n",
      "idx: 190, loss: 0.5889283418655396\n",
      "idx: 200, loss: 0.4809494614601135\n",
      "idx: 210, loss: 0.5820706486701965\n",
      "idx: 220, loss: 0.5966067314147949\n",
      "idx: 230, loss: 0.490752637386322\n",
      "idx: 0, loss: 0.4696166515350342\n",
      "idx: 10, loss: 0.5688652396202087\n",
      "idx: 20, loss: 0.5666639804840088\n",
      "idx: 30, loss: 0.47536152601242065\n",
      "idx: 40, loss: 0.5687108635902405\n",
      "idx: 50, loss: 0.3879047632217407\n",
      "idx: 60, loss: 0.48088040947914124\n",
      "idx: 70, loss: 0.5915902256965637\n",
      "idx: 80, loss: 0.5365867614746094\n",
      "idx: 90, loss: 0.5329480171203613\n",
      "idx: 100, loss: 0.48686471581459045\n",
      "idx: 110, loss: 0.5705191493034363\n",
      "idx: 120, loss: 0.5756453275680542\n",
      "idx: 130, loss: 0.5221059322357178\n",
      "idx: 140, loss: 0.4980718195438385\n",
      "idx: 150, loss: 0.4412015378475189\n",
      "idx: 160, loss: 0.5652711391448975\n",
      "idx: 170, loss: 0.431360125541687\n",
      "idx: 180, loss: 0.5015621781349182\n",
      "idx: 190, loss: 0.5280358791351318\n",
      "idx: 200, loss: 0.4325452148914337\n",
      "idx: 210, loss: 0.5523918271064758\n",
      "idx: 220, loss: 0.5408607125282288\n",
      "idx: 230, loss: 0.4399375021457672\n",
      "idx: 0, loss: 0.41584786772727966\n",
      "idx: 10, loss: 0.5326511263847351\n",
      "idx: 20, loss: 0.5127789974212646\n",
      "idx: 30, loss: 0.422930508852005\n",
      "idx: 40, loss: 0.5233182907104492\n",
      "idx: 50, loss: 0.3485352098941803\n",
      "idx: 60, loss: 0.44293445348739624\n",
      "idx: 70, loss: 0.5526374578475952\n",
      "idx: 80, loss: 0.4968600869178772\n",
      "idx: 90, loss: 0.4983023703098297\n",
      "idx: 100, loss: 0.44034701585769653\n",
      "idx: 110, loss: 0.5280093550682068\n",
      "idx: 120, loss: 0.5098322033882141\n",
      "idx: 130, loss: 0.4891098141670227\n",
      "idx: 140, loss: 0.48461005091667175\n",
      "idx: 150, loss: 0.3985506296157837\n",
      "idx: 160, loss: 0.4986499547958374\n",
      "idx: 170, loss: 0.39705824851989746\n",
      "idx: 180, loss: 0.46883782744407654\n",
      "idx: 190, loss: 0.4918816387653351\n",
      "idx: 200, loss: 0.4139983355998993\n",
      "idx: 210, loss: 0.5227881669998169\n",
      "idx: 220, loss: 0.5057974457740784\n",
      "idx: 230, loss: 0.4063955843448639\n",
      "idx: 0, loss: 0.38393333554267883\n",
      "idx: 10, loss: 0.5079513192176819\n",
      "idx: 20, loss: 0.4767245650291443\n",
      "idx: 30, loss: 0.3857257664203644\n",
      "idx: 40, loss: 0.49119827151298523\n",
      "idx: 50, loss: 0.3275368809700012\n",
      "idx: 60, loss: 0.41986432671546936\n",
      "idx: 70, loss: 0.5356886386871338\n",
      "idx: 80, loss: 0.4653167724609375\n",
      "idx: 90, loss: 0.47719573974609375\n",
      "idx: 100, loss: 0.4026661217212677\n",
      "idx: 110, loss: 0.49408066272735596\n",
      "idx: 120, loss: 0.4886784851551056\n",
      "idx: 130, loss: 0.4681970477104187\n",
      "idx: 140, loss: 0.4665319621562958\n",
      "idx: 150, loss: 0.3697577118873596\n",
      "idx: 160, loss: 0.4773660898208618\n",
      "idx: 170, loss: 0.3713900148868561\n",
      "idx: 180, loss: 0.45285993814468384\n",
      "idx: 190, loss: 0.4615609645843506\n",
      "idx: 200, loss: 0.40731269121170044\n",
      "idx: 210, loss: 0.5136940479278564\n",
      "idx: 220, loss: 0.47520211338996887\n",
      "idx: 230, loss: 0.3730314373970032\n",
      "idx: 0, loss: 0.3709954619407654\n",
      "idx: 10, loss: 0.4898330569267273\n",
      "idx: 20, loss: 0.4563969671726227\n",
      "idx: 30, loss: 0.3605574667453766\n",
      "idx: 40, loss: 0.46522051095962524\n",
      "idx: 50, loss: 0.3110601007938385\n",
      "idx: 60, loss: 0.4024573564529419\n",
      "idx: 70, loss: 0.509185791015625\n",
      "idx: 80, loss: 0.4445377588272095\n",
      "idx: 90, loss: 0.45083189010620117\n",
      "idx: 100, loss: 0.38173308968544006\n",
      "idx: 110, loss: 0.4646947979927063\n",
      "idx: 120, loss: 0.46241942048072815\n",
      "idx: 130, loss: 0.45272213220596313\n",
      "idx: 140, loss: 0.4557975232601166\n",
      "idx: 150, loss: 0.35274046659469604\n",
      "idx: 160, loss: 0.4474043548107147\n",
      "idx: 170, loss: 0.3566339612007141\n",
      "idx: 180, loss: 0.4344452917575836\n",
      "idx: 190, loss: 0.43656694889068604\n",
      "idx: 200, loss: 0.40519776940345764\n",
      "idx: 210, loss: 0.4893040060997009\n",
      "idx: 220, loss: 0.45523759722709656\n",
      "idx: 230, loss: 0.35651612281799316\n",
      "idx: 0, loss: 0.3524715304374695\n",
      "idx: 10, loss: 0.4747776985168457\n",
      "idx: 20, loss: 0.44212791323661804\n",
      "idx: 30, loss: 0.34506577253341675\n",
      "idx: 40, loss: 0.44384634494781494\n",
      "idx: 50, loss: 0.29412174224853516\n",
      "idx: 60, loss: 0.3963780105113983\n",
      "idx: 70, loss: 0.49095290899276733\n",
      "idx: 80, loss: 0.42406195402145386\n",
      "idx: 90, loss: 0.44475916028022766\n",
      "idx: 100, loss: 0.3617747128009796\n",
      "idx: 110, loss: 0.44696345925331116\n",
      "idx: 120, loss: 0.44419151544570923\n",
      "idx: 130, loss: 0.4338826835155487\n",
      "idx: 140, loss: 0.4390460252761841\n",
      "idx: 150, loss: 0.34122252464294434\n",
      "idx: 160, loss: 0.4184589087963104\n",
      "idx: 170, loss: 0.3405086100101471\n",
      "idx: 180, loss: 0.4264671504497528\n",
      "idx: 190, loss: 0.4220390319824219\n",
      "idx: 200, loss: 0.3903661370277405\n",
      "idx: 210, loss: 0.472427099943161\n",
      "idx: 220, loss: 0.4296756386756897\n",
      "idx: 230, loss: 0.34512606263160706\n",
      "idx: 0, loss: 0.33892711997032166\n",
      "idx: 10, loss: 0.46170690655708313\n",
      "idx: 20, loss: 0.43054383993148804\n",
      "idx: 30, loss: 0.33316075801849365\n",
      "idx: 40, loss: 0.42729270458221436\n",
      "idx: 50, loss: 0.2799563407897949\n",
      "idx: 60, loss: 0.3874095678329468\n",
      "idx: 70, loss: 0.4732368588447571\n",
      "idx: 80, loss: 0.407992422580719\n",
      "idx: 90, loss: 0.45066604018211365\n",
      "idx: 100, loss: 0.34861716628074646\n",
      "idx: 110, loss: 0.43750566244125366\n",
      "idx: 120, loss: 0.42977961897850037\n",
      "idx: 130, loss: 0.4163239002227783\n",
      "idx: 140, loss: 0.433332622051239\n",
      "idx: 150, loss: 0.33209413290023804\n",
      "idx: 160, loss: 0.39977166056632996\n",
      "idx: 170, loss: 0.3301629424095154\n",
      "idx: 180, loss: 0.41130518913269043\n",
      "idx: 190, loss: 0.4045008420944214\n",
      "idx: 200, loss: 0.3834664225578308\n",
      "idx: 210, loss: 0.4538539946079254\n",
      "idx: 220, loss: 0.415790319442749\n",
      "idx: 230, loss: 0.33812782168388367\n",
      "idx: 0, loss: 0.33128905296325684\n",
      "idx: 10, loss: 0.448700487613678\n",
      "idx: 20, loss: 0.422005832195282\n",
      "idx: 30, loss: 0.32376226782798767\n",
      "idx: 40, loss: 0.4108482301235199\n",
      "idx: 50, loss: 0.26625439524650574\n",
      "idx: 60, loss: 0.38231009244918823\n",
      "idx: 70, loss: 0.454196035861969\n",
      "idx: 80, loss: 0.39701467752456665\n",
      "idx: 90, loss: 0.43579015135765076\n",
      "idx: 100, loss: 0.33774903416633606\n",
      "idx: 110, loss: 0.4243951141834259\n",
      "idx: 120, loss: 0.41801610589027405\n",
      "idx: 130, loss: 0.4033612012863159\n",
      "idx: 140, loss: 0.4230923652648926\n",
      "idx: 150, loss: 0.32352662086486816\n",
      "idx: 160, loss: 0.38689106702804565\n",
      "idx: 170, loss: 0.3221603333950043\n",
      "idx: 180, loss: 0.40399807691574097\n",
      "idx: 190, loss: 0.3979138135910034\n",
      "idx: 200, loss: 0.38053515553474426\n",
      "idx: 210, loss: 0.42985984683036804\n",
      "idx: 220, loss: 0.3982325494289398\n",
      "idx: 230, loss: 0.33227139711380005\n",
      "idx: 0, loss: 0.32423195242881775\n",
      "idx: 10, loss: 0.44074028730392456\n",
      "idx: 20, loss: 0.4150868356227875\n",
      "idx: 30, loss: 0.3144519329071045\n",
      "idx: 40, loss: 0.3979557454586029\n",
      "idx: 50, loss: 0.25297462940216064\n",
      "idx: 60, loss: 0.37512627243995667\n",
      "idx: 70, loss: 0.44382694363594055\n",
      "idx: 80, loss: 0.38700297474861145\n",
      "idx: 90, loss: 0.42673927545547485\n",
      "idx: 100, loss: 0.330226868391037\n",
      "idx: 110, loss: 0.41382896900177\n",
      "idx: 120, loss: 0.40345752239227295\n",
      "idx: 130, loss: 0.3875705599784851\n",
      "idx: 140, loss: 0.4225790798664093\n",
      "idx: 150, loss: 0.3182612955570221\n",
      "idx: 160, loss: 0.3817976415157318\n",
      "idx: 170, loss: 0.31336456537246704\n",
      "idx: 180, loss: 0.39646115899086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 190, loss: 0.38177046179771423\n",
      "idx: 200, loss: 0.3712058961391449\n",
      "idx: 210, loss: 0.4158327877521515\n",
      "idx: 220, loss: 0.3888995051383972\n",
      "idx: 230, loss: 0.32496964931488037\n",
      "idx: 0, loss: 0.3131815791130066\n",
      "idx: 10, loss: 0.42888984084129333\n",
      "idx: 20, loss: 0.4072033762931824\n",
      "idx: 30, loss: 0.3043828308582306\n",
      "idx: 40, loss: 0.38510745763778687\n",
      "idx: 50, loss: 0.2433207631111145\n",
      "idx: 60, loss: 0.3633122146129608\n",
      "idx: 70, loss: 0.4200317859649658\n",
      "idx: 80, loss: 0.37663888931274414\n",
      "idx: 90, loss: 0.4038744568824768\n",
      "idx: 100, loss: 0.3173879086971283\n",
      "idx: 110, loss: 0.3997277617454529\n",
      "idx: 120, loss: 0.3947860598564148\n",
      "idx: 130, loss: 0.3779008686542511\n",
      "idx: 140, loss: 0.4064907133579254\n",
      "idx: 150, loss: 0.3068082332611084\n",
      "idx: 160, loss: 0.3665972650051117\n",
      "idx: 170, loss: 0.30494067072868347\n",
      "idx: 180, loss: 0.38813477754592896\n",
      "idx: 190, loss: 0.3628680109977722\n",
      "idx: 200, loss: 0.36767321825027466\n",
      "idx: 210, loss: 0.39615631103515625\n",
      "idx: 220, loss: 0.3738441467285156\n",
      "idx: 230, loss: 0.3154037296772003\n",
      "Epoch 10. LR: 0.088125. Loss: 0.2795 Accuracy 0.8654\n",
      "idx: 0, loss: 0.29524996876716614\n",
      "idx: 10, loss: 0.4202716052532196\n",
      "idx: 20, loss: 0.3988364040851593\n",
      "idx: 30, loss: 0.2965588867664337\n",
      "idx: 40, loss: 0.37393924593925476\n",
      "idx: 50, loss: 0.23571190237998962\n",
      "idx: 60, loss: 0.35752540826797485\n",
      "idx: 70, loss: 0.4051402807235718\n",
      "idx: 80, loss: 0.3664880096912384\n",
      "idx: 90, loss: 0.38528716564178467\n",
      "idx: 100, loss: 0.30578580498695374\n",
      "idx: 110, loss: 0.3865642845630646\n",
      "idx: 120, loss: 0.38218724727630615\n",
      "idx: 130, loss: 0.3679072856903076\n",
      "idx: 140, loss: 0.39856472611427307\n",
      "idx: 150, loss: 0.29713085293769836\n",
      "idx: 160, loss: 0.3530745804309845\n",
      "idx: 170, loss: 0.2976485788822174\n",
      "idx: 180, loss: 0.3796704411506653\n",
      "idx: 190, loss: 0.3515312373638153\n",
      "idx: 200, loss: 0.35947084426879883\n",
      "idx: 210, loss: 0.38348349928855896\n",
      "idx: 220, loss: 0.3629727065563202\n",
      "idx: 230, loss: 0.3105309307575226\n",
      "idx: 0, loss: 0.2857382893562317\n",
      "idx: 10, loss: 0.41333696246147156\n",
      "idx: 20, loss: 0.3918974995613098\n",
      "idx: 30, loss: 0.29114675521850586\n",
      "idx: 40, loss: 0.3638637065887451\n",
      "idx: 50, loss: 0.22924818098545074\n",
      "idx: 60, loss: 0.35117921233177185\n",
      "idx: 70, loss: 0.3961220383644104\n",
      "idx: 80, loss: 0.35245418548583984\n",
      "idx: 90, loss: 0.3695151209831238\n",
      "idx: 100, loss: 0.2981041669845581\n",
      "idx: 110, loss: 0.38036033511161804\n",
      "idx: 120, loss: 0.3757244050502777\n",
      "idx: 130, loss: 0.3588114380836487\n",
      "idx: 140, loss: 0.3892501890659332\n",
      "idx: 150, loss: 0.28877779841423035\n",
      "idx: 160, loss: 0.3434770703315735\n",
      "idx: 170, loss: 0.2886658310890198\n",
      "idx: 180, loss: 0.372604638338089\n",
      "idx: 190, loss: 0.34022215008735657\n",
      "idx: 200, loss: 0.35353556275367737\n",
      "idx: 210, loss: 0.369808167219162\n",
      "idx: 220, loss: 0.3558433949947357\n",
      "idx: 230, loss: 0.3044261336326599\n",
      "idx: 0, loss: 0.27820467948913574\n",
      "idx: 10, loss: 0.4061356782913208\n",
      "idx: 20, loss: 0.3862166404724121\n",
      "idx: 30, loss: 0.28808465600013733\n",
      "idx: 40, loss: 0.3557731509208679\n",
      "idx: 50, loss: 0.22379690408706665\n",
      "idx: 60, loss: 0.3465120494365692\n",
      "idx: 70, loss: 0.38695988059043884\n",
      "idx: 80, loss: 0.34285759925842285\n",
      "idx: 90, loss: 0.35873666405677795\n",
      "idx: 100, loss: 0.2936444878578186\n",
      "idx: 110, loss: 0.37269988656044006\n",
      "idx: 120, loss: 0.37282440066337585\n",
      "idx: 130, loss: 0.3505280017852783\n",
      "idx: 140, loss: 0.3818109929561615\n",
      "idx: 150, loss: 0.28240248560905457\n",
      "idx: 160, loss: 0.33771178126335144\n",
      "idx: 170, loss: 0.2813992202281952\n",
      "idx: 180, loss: 0.3667997717857361\n",
      "idx: 190, loss: 0.32961687445640564\n",
      "idx: 200, loss: 0.34939059615135193\n",
      "idx: 210, loss: 0.3609360158443451\n",
      "idx: 220, loss: 0.34979119896888733\n",
      "idx: 230, loss: 0.3007221221923828\n",
      "idx: 0, loss: 0.27433720231056213\n",
      "idx: 10, loss: 0.4006551504135132\n",
      "idx: 20, loss: 0.3786814510822296\n",
      "idx: 30, loss: 0.2855771780014038\n",
      "idx: 40, loss: 0.34860315918922424\n",
      "idx: 50, loss: 0.22025062143802643\n",
      "idx: 60, loss: 0.34390926361083984\n",
      "idx: 70, loss: 0.38057374954223633\n",
      "idx: 80, loss: 0.3362163305282593\n",
      "idx: 90, loss: 0.35145050287246704\n",
      "idx: 100, loss: 0.2912583649158478\n",
      "idx: 110, loss: 0.36679601669311523\n",
      "idx: 120, loss: 0.36893364787101746\n",
      "idx: 130, loss: 0.3454616963863373\n",
      "idx: 140, loss: 0.3753588795661926\n",
      "idx: 150, loss: 0.2780844569206238\n",
      "idx: 160, loss: 0.3320956826210022\n",
      "idx: 170, loss: 0.273818701505661\n",
      "idx: 180, loss: 0.36350202560424805\n",
      "idx: 190, loss: 0.3224462866783142\n",
      "idx: 200, loss: 0.347140908241272\n",
      "idx: 210, loss: 0.350544273853302\n",
      "idx: 220, loss: 0.3442635238170624\n",
      "idx: 230, loss: 0.2985474169254303\n",
      "idx: 0, loss: 0.2690267860889435\n",
      "idx: 10, loss: 0.3966311514377594\n",
      "idx: 20, loss: 0.37295642495155334\n",
      "idx: 30, loss: 0.2824641168117523\n",
      "idx: 40, loss: 0.34388288855552673\n",
      "idx: 50, loss: 0.21645085513591766\n",
      "idx: 60, loss: 0.33967408537864685\n",
      "idx: 70, loss: 0.37320026755332947\n",
      "idx: 80, loss: 0.3313102126121521\n",
      "idx: 90, loss: 0.3467133939266205\n",
      "idx: 100, loss: 0.2921653985977173\n",
      "idx: 110, loss: 0.3629974126815796\n",
      "idx: 120, loss: 0.3657291829586029\n",
      "idx: 130, loss: 0.34168004989624023\n",
      "idx: 140, loss: 0.3692721724510193\n",
      "idx: 150, loss: 0.2738732099533081\n",
      "idx: 160, loss: 0.32846587896347046\n",
      "idx: 170, loss: 0.26667964458465576\n",
      "idx: 180, loss: 0.3609403073787689\n",
      "idx: 190, loss: 0.31733375787734985\n",
      "idx: 200, loss: 0.34675413370132446\n",
      "idx: 210, loss: 0.3470742106437683\n",
      "idx: 220, loss: 0.33985158801078796\n",
      "idx: 230, loss: 0.29706406593322754\n",
      "idx: 0, loss: 0.2648465931415558\n",
      "idx: 10, loss: 0.3945123553276062\n",
      "idx: 20, loss: 0.36825650930404663\n",
      "idx: 30, loss: 0.2804405987262726\n",
      "idx: 40, loss: 0.33786633610725403\n",
      "idx: 50, loss: 0.21558868885040283\n",
      "idx: 60, loss: 0.3363254964351654\n",
      "idx: 70, loss: 0.36603978276252747\n",
      "idx: 80, loss: 0.32931581139564514\n",
      "idx: 90, loss: 0.34175583720207214\n",
      "idx: 100, loss: 0.29391804337501526\n",
      "idx: 110, loss: 0.3605495095252991\n",
      "idx: 120, loss: 0.3655988574028015\n",
      "idx: 130, loss: 0.3389337658882141\n",
      "idx: 140, loss: 0.36730554699897766\n",
      "idx: 150, loss: 0.27123281359672546\n",
      "idx: 160, loss: 0.326471209526062\n",
      "idx: 170, loss: 0.2603374123573303\n",
      "idx: 180, loss: 0.35929974913597107\n",
      "idx: 190, loss: 0.3144005537033081\n",
      "idx: 200, loss: 0.34596124291419983\n",
      "idx: 210, loss: 0.3436698615550995\n",
      "idx: 220, loss: 0.33558857440948486\n",
      "idx: 230, loss: 0.293534517288208\n",
      "idx: 0, loss: 0.2626141607761383\n",
      "idx: 10, loss: 0.39559340476989746\n",
      "idx: 20, loss: 0.3619912564754486\n",
      "idx: 30, loss: 0.2807903289794922\n",
      "idx: 40, loss: 0.33292606472969055\n",
      "idx: 50, loss: 0.2134793996810913\n",
      "idx: 60, loss: 0.33378294110298157\n",
      "idx: 70, loss: 0.3626737594604492\n",
      "idx: 80, loss: 0.32981204986572266\n",
      "idx: 90, loss: 0.33836737275123596\n",
      "idx: 100, loss: 0.2952887713909149\n",
      "idx: 110, loss: 0.36033394932746887\n",
      "idx: 120, loss: 0.365223228931427\n",
      "idx: 130, loss: 0.332878440618515\n",
      "idx: 140, loss: 0.36633777618408203\n",
      "idx: 150, loss: 0.2675187289714813\n",
      "idx: 160, loss: 0.326574444770813\n",
      "idx: 170, loss: 0.2563495635986328\n",
      "idx: 180, loss: 0.3594612777233124\n",
      "idx: 190, loss: 0.31556764245033264\n",
      "idx: 200, loss: 0.34421610832214355\n",
      "idx: 210, loss: 0.3389256000518799\n",
      "idx: 220, loss: 0.33581745624542236\n",
      "idx: 230, loss: 0.28022879362106323\n",
      "idx: 0, loss: 0.2616511285305023\n",
      "idx: 10, loss: 0.39413708448410034\n",
      "idx: 20, loss: 0.3600131869316101\n",
      "idx: 30, loss: 0.280130535364151\n",
      "idx: 40, loss: 0.33148330450057983\n",
      "idx: 50, loss: 0.21299052238464355\n",
      "idx: 60, loss: 0.3321235775947571\n",
      "idx: 70, loss: 0.36142921447753906\n",
      "idx: 80, loss: 0.32946068048477173\n",
      "idx: 90, loss: 0.33892881870269775\n",
      "idx: 100, loss: 0.2949937880039215\n",
      "idx: 110, loss: 0.36007893085479736\n",
      "idx: 120, loss: 0.36469241976737976\n",
      "idx: 130, loss: 0.33248478174209595\n",
      "idx: 140, loss: 0.36581823229789734\n",
      "idx: 150, loss: 0.26751965284347534\n",
      "idx: 160, loss: 0.32597967982292175\n",
      "idx: 170, loss: 0.2563481330871582\n",
      "idx: 180, loss: 0.35941436886787415\n",
      "idx: 190, loss: 0.31486955285072327\n",
      "idx: 200, loss: 0.3438493013381958\n",
      "idx: 210, loss: 0.33875352144241333\n",
      "idx: 220, loss: 0.3359370231628418\n",
      "idx: 230, loss: 0.28044575452804565\n",
      "idx: 0, loss: 0.2613825798034668\n",
      "idx: 10, loss: 0.3938939869403839\n",
      "idx: 20, loss: 0.35918569564819336\n",
      "idx: 30, loss: 0.27993419766426086\n",
      "idx: 40, loss: 0.33076411485671997\n",
      "idx: 50, loss: 0.2126053422689438\n",
      "idx: 60, loss: 0.3315991759300232\n",
      "idx: 70, loss: 0.3609175980091095\n",
      "idx: 80, loss: 0.32892823219299316\n",
      "idx: 90, loss: 0.3386341333389282\n",
      "idx: 100, loss: 0.29487475752830505\n",
      "idx: 110, loss: 0.35994625091552734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 120, loss: 0.36438965797424316\n",
      "idx: 130, loss: 0.3318856656551361\n",
      "idx: 140, loss: 0.36542314291000366\n",
      "idx: 150, loss: 0.2672811448574066\n",
      "idx: 160, loss: 0.3255382180213928\n",
      "idx: 170, loss: 0.25614336133003235\n",
      "idx: 180, loss: 0.35927778482437134\n",
      "idx: 190, loss: 0.31431594491004944\n",
      "idx: 200, loss: 0.3433908224105835\n",
      "idx: 210, loss: 0.33842939138412476\n",
      "idx: 220, loss: 0.33584901690483093\n",
      "idx: 230, loss: 0.28026729822158813\n",
      "Epoch 19. LR: 0.005. Loss: 0.2322 Accuracy 0.8756\n"
     ]
    }
   ],
   "source": [
    "general_model = model_cfg.base(*model_cfg.args, **model_cfg.kwargs)\n",
    "title_pretrained_init = \"pretrained_init\" + title\n",
    "\n",
    "if not pretrained_init:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(general_model.parameters(), lr=1e-1)\n",
    "    wd = 0.0\n",
    "    lr_init = 1e-1\n",
    "    train(general_model, train_loader, test_loader, optimizer, criterion, lr_init, title=title_pretrained_init, epochs=20)\n",
    "else:\n",
    "    general_model.load_state_dict(torch.load(\"ckpts/\" + title_pretrained_init + \".pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x576 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "client_loaders = noniid_datasets(train_loader, n_clients=10, n_classes=10)\n",
    "visualizing_client_loader(client_loaders, n_clients, n_classes, path_figures=\"./figures/\"+title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_clients = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.35091689229011536\n",
      "idx: 10, loss: 0.28695061802864075\n",
      "Epoch 0. LR: 0.005. Loss: 0.2870 Accuracy 0.8693\n",
      "idx: 0, loss: 0.1568729430437088\n",
      "idx: 10, loss: 0.3214471638202667\n",
      "idx: 20, loss: 0.2638384997844696\n",
      "Epoch 0. LR: 0.005. Loss: 0.2244 Accuracy 0.8758\n",
      "idx: 0, loss: 0.48397719860076904\n",
      "idx: 10, loss: 0.30703821778297424\n",
      "idx: 20, loss: 0.3471637964248657\n",
      "idx: 30, loss: 0.07762376964092255\n",
      "Epoch 0. LR: 0.005. Loss: 0.0776 Accuracy 0.8605\n",
      "idx: 0, loss: 0.3220568299293518\n",
      "idx: 10, loss: 0.4040733575820923\n",
      "idx: 20, loss: 0.34391146898269653\n",
      "idx: 30, loss: 0.3611721992492676\n",
      "idx: 40, loss: 0.22277775406837463\n",
      "idx: 50, loss: 0.15597577393054962\n",
      "idx: 60, loss: 0.352388858795166\n",
      "Epoch 0. LR: 0.005. Loss: 0.1207 Accuracy 0.8698\n",
      "idx: 0, loss: 0.24345555901527405\n",
      "idx: 10, loss: 0.26012277603149414\n",
      "idx: 20, loss: 0.36578869819641113\n",
      "idx: 30, loss: 0.3245038092136383\n",
      "idx: 40, loss: 0.32879742980003357\n",
      "idx: 50, loss: 0.3378928303718567\n",
      "idx: 60, loss: 0.43215715885162354\n",
      "idx: 70, loss: 0.2587205171585083\n",
      "idx: 80, loss: 0.2252294421195984\n",
      "idx: 90, loss: 0.14769747853279114\n",
      "idx: 100, loss: 0.28479400277137756\n",
      "Epoch 0. LR: 0.005. Loss: 0.1340 Accuracy 0.8619\n",
      "idx: 0, loss: 0.47071558237075806\n",
      "idx: 10, loss: 0.38387125730514526\n",
      "idx: 20, loss: 0.1749272644519806\n",
      "idx: 30, loss: 0.38039472699165344\n",
      "idx: 40, loss: 0.3792697787284851\n",
      "idx: 50, loss: 0.41209515929222107\n",
      "idx: 60, loss: 0.243258535861969\n",
      "idx: 70, loss: 0.3752157390117645\n",
      "idx: 80, loss: 0.18377837538719177\n",
      "idx: 90, loss: 0.3749338686466217\n",
      "idx: 100, loss: 0.3956582546234131\n",
      "Epoch 0. LR: 0.005. Loss: 0.2343 Accuracy 0.8725\n",
      "idx: 0, loss: 0.42427101731300354\n",
      "idx: 10, loss: 0.3859201669692993\n",
      "idx: 20, loss: 0.496086984872818\n",
      "idx: 30, loss: 0.3710503578186035\n",
      "idx: 40, loss: 0.31194907426834106\n",
      "idx: 50, loss: 0.463087797164917\n",
      "idx: 60, loss: 0.40108051896095276\n",
      "idx: 70, loss: 0.323753297328949\n",
      "idx: 80, loss: 0.3235674202442169\n",
      "idx: 90, loss: 0.31376251578330994\n",
      "idx: 100, loss: 0.3653106093406677\n",
      "idx: 110, loss: 0.2598472833633423\n",
      "idx: 120, loss: 0.544996976852417\n",
      "Epoch 0. LR: 0.005. Loss: 0.3271 Accuracy 0.8604\n",
      "idx: 0, loss: 0.19859714806079865\n",
      "idx: 10, loss: 0.29566261172294617\n",
      "idx: 20, loss: 0.3784179091453552\n",
      "idx: 30, loss: 0.31434378027915955\n",
      "idx: 40, loss: 0.172408327460289\n",
      "idx: 50, loss: 0.24243281781673431\n",
      "idx: 60, loss: 0.3483510911464691\n",
      "idx: 70, loss: 0.24333803355693817\n",
      "idx: 80, loss: 0.20369555056095123\n",
      "idx: 90, loss: 0.4198831617832184\n",
      "idx: 100, loss: 0.2347777783870697\n",
      "idx: 110, loss: 0.327433705329895\n",
      "idx: 120, loss: 0.38178735971450806\n",
      "idx: 130, loss: 0.2994525730609894\n",
      "Epoch 0. LR: 0.005. Loss: 0.3680 Accuracy 0.8730\n",
      "idx: 0, loss: 0.21958822011947632\n",
      "idx: 10, loss: 0.32595178484916687\n",
      "idx: 20, loss: 0.3298157751560211\n",
      "idx: 30, loss: 0.29520469903945923\n",
      "idx: 40, loss: 0.3413419723510742\n",
      "idx: 50, loss: 0.18030045926570892\n",
      "idx: 60, loss: 0.28089410066604614\n",
      "idx: 70, loss: 0.45929375290870667\n",
      "idx: 80, loss: 0.2131497859954834\n",
      "idx: 90, loss: 0.18269258737564087\n",
      "idx: 100, loss: 0.20627182722091675\n",
      "idx: 110, loss: 0.14452412724494934\n",
      "idx: 120, loss: 0.17292428016662598\n",
      "idx: 130, loss: 0.3249467611312866\n",
      "idx: 140, loss: 0.28748488426208496\n",
      "idx: 150, loss: 0.29645025730133057\n",
      "Epoch 0. LR: 0.005. Loss: 0.1450 Accuracy 0.8719\n",
      "idx: 0, loss: 0.24597898125648499\n",
      "idx: 10, loss: 0.3323500156402588\n",
      "idx: 20, loss: 0.26874983310699463\n",
      "idx: 30, loss: 0.25193309783935547\n",
      "idx: 40, loss: 0.2685978412628174\n",
      "idx: 50, loss: 0.39463260769844055\n",
      "idx: 60, loss: 0.2151690125465393\n",
      "idx: 70, loss: 0.2892409861087799\n",
      "idx: 80, loss: 0.2264733463525772\n",
      "idx: 90, loss: 0.27059444785118103\n",
      "idx: 100, loss: 0.29718253016471863\n",
      "idx: 110, loss: 0.1598716378211975\n",
      "idx: 120, loss: 0.2151554375886917\n",
      "idx: 130, loss: 0.2244521528482437\n",
      "idx: 140, loss: 0.28407835960388184\n",
      "idx: 150, loss: 0.5115898251533508\n",
      "idx: 160, loss: 0.3627360165119171\n",
      "Epoch 0. LR: 0.005. Loss: 0.2792 Accuracy 0.8710\n"
     ]
    }
   ],
   "source": [
    "if not pretrained_clients:\n",
    "    s = sum(1 for _ in general_model.parameters())\n",
    "    for i in range(n_clients):\n",
    "        loader_i = client_loaders[i]\n",
    "        model = model_cfg.base(*model_cfg.args, **model_cfg.kwargs)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "        for j, (param, param_client) in enumerate(zip(model.parameters(), general_model.parameters())):\n",
    "            if j <= s - 2: #we do not wish to copy/clone the weights of the last layer (logistic regression layer in the report)\n",
    "                param.data = param_client.data.clone()\n",
    "        title_i = \"parametrized_preclient_\" + title + str(i)\n",
    "        wd = 0.0\n",
    "        lr_init = 1e-1\n",
    "        train(model, loader_i, test_loader, optimizer, criterion, lr_init, title=title_i, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [SWAG(model_cfg.base, subspace_type=\"pca\", *model_cfg.args, **model_cfg.kwargs, \n",
    "                  subspace_kwargs={\"max_rank\": 2, \"pca_rank\": 2}) for i in range(n_clients)]\n",
    "probs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.3100248873233795\n",
      "idx: 10, loss: 0.27731502056121826\n",
      "Epoch 0. LR: 0.01. Loss: 0.2773 Accuracy 0.8685\n",
      "idx: 0, loss: 0.2944023013114929\n",
      "idx: 10, loss: 0.2697295844554901\n",
      "idx: 0, loss: 0.2850557863712311\n",
      "idx: 10, loss: 0.2635791599750519\n",
      "idx: 0, loss: 0.27559253573417664\n",
      "idx: 10, loss: 0.2568063735961914\n",
      "idx: 0, loss: 0.2673250138759613\n",
      "idx: 10, loss: 0.25174635648727417\n",
      "Epoch 4. LR: 0.01. Loss: 0.2517 Accuracy 0.8641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:368: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.14081235229969025\n",
      "idx: 10, loss: 0.30486565828323364\n",
      "idx: 20, loss: 0.2619249224662781\n",
      "Epoch 0. LR: 0.01. Loss: 0.2331 Accuracy 0.8752\n",
      "idx: 0, loss: 0.13646182417869568\n",
      "idx: 10, loss: 0.29368460178375244\n",
      "idx: 20, loss: 0.26274120807647705\n",
      "idx: 0, loss: 0.13339312374591827\n",
      "idx: 10, loss: 0.2877889573574066\n",
      "idx: 20, loss: 0.26225027441978455\n",
      "idx: 0, loss: 0.13230085372924805\n",
      "idx: 10, loss: 0.28437289595603943\n",
      "idx: 20, loss: 0.2610507309436798\n",
      "idx: 0, loss: 0.13128601014614105\n",
      "idx: 10, loss: 0.2812546491622925\n",
      "idx: 20, loss: 0.2590392231941223\n",
      "Epoch 4. LR: 0.01. Loss: 0.2377 Accuracy 0.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:368: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.29687729477882385\n",
      "idx: 10, loss: 0.292668879032135\n",
      "idx: 20, loss: 0.3564232289791107\n",
      "idx: 30, loss: 0.07503203302621841\n",
      "Epoch 0. LR: 0.01. Loss: 0.0750 Accuracy 0.8583\n",
      "idx: 0, loss: 0.29300740361213684\n",
      "idx: 10, loss: 0.28436964750289917\n",
      "idx: 20, loss: 0.3537410497665405\n",
      "idx: 30, loss: 0.07413073629140854\n",
      "idx: 0, loss: 0.28463026881217957\n",
      "idx: 10, loss: 0.27887028455734253\n",
      "idx: 20, loss: 0.35199257731437683\n",
      "idx: 30, loss: 0.07310491055250168\n",
      "idx: 0, loss: 0.2774404287338257\n",
      "idx: 10, loss: 0.27483266592025757\n",
      "idx: 20, loss: 0.34828320145606995\n",
      "idx: 30, loss: 0.07245494425296783\n",
      "idx: 0, loss: 0.2725970149040222\n",
      "idx: 10, loss: 0.2707009017467499\n",
      "idx: 20, loss: 0.3466954827308655\n",
      "idx: 30, loss: 0.07134085148572922\n",
      "Epoch 4. LR: 0.01. Loss: 0.0713 Accuracy 0.8550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:368: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.3086371123790741\n",
      "idx: 10, loss: 0.40559104084968567\n",
      "idx: 20, loss: 0.3405556082725525\n",
      "idx: 30, loss: 0.3551018238067627\n",
      "idx: 40, loss: 0.2144816666841507\n",
      "idx: 50, loss: 0.15662170946598053\n",
      "idx: 60, loss: 0.35459843277931213\n",
      "Epoch 0. LR: 0.01. Loss: 0.0803 Accuracy 0.8667\n",
      "idx: 0, loss: 0.3146474361419678\n",
      "idx: 10, loss: 0.4080115854740143\n",
      "idx: 20, loss: 0.3325570821762085\n",
      "idx: 30, loss: 0.3514471650123596\n",
      "idx: 40, loss: 0.21036012470722198\n",
      "idx: 50, loss: 0.15192511677742004\n",
      "idx: 60, loss: 0.34963229298591614\n",
      "idx: 0, loss: 0.30990228056907654\n",
      "idx: 10, loss: 0.40364834666252136\n",
      "idx: 20, loss: 0.3265131711959839\n",
      "idx: 30, loss: 0.34853261709213257\n",
      "idx: 40, loss: 0.20891684293746948\n",
      "idx: 50, loss: 0.1494792252779007\n",
      "idx: 60, loss: 0.3476732671260834\n",
      "idx: 0, loss: 0.30736252665519714\n",
      "idx: 10, loss: 0.3995477855205536\n",
      "idx: 20, loss: 0.3221918046474457\n",
      "idx: 30, loss: 0.3457663059234619\n",
      "idx: 40, loss: 0.2086775153875351\n",
      "idx: 50, loss: 0.14743484556674957\n",
      "idx: 60, loss: 0.3466395139694214\n",
      "idx: 0, loss: 0.30548733472824097\n",
      "idx: 10, loss: 0.39503684639930725\n",
      "idx: 20, loss: 0.31811031699180603\n",
      "idx: 30, loss: 0.3430109918117523\n",
      "idx: 40, loss: 0.20771586894989014\n",
      "idx: 50, loss: 0.14593182504177094\n",
      "idx: 60, loss: 0.3432767987251282\n",
      "Epoch 4. LR: 0.01. Loss: 0.0511 Accuracy 0.8667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:368: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.24007399380207062\n",
      "idx: 10, loss: 0.24811801314353943\n",
      "idx: 20, loss: 0.3747132122516632\n",
      "idx: 30, loss: 0.32207778096199036\n",
      "idx: 40, loss: 0.32950559258461\n",
      "idx: 50, loss: 0.3361320197582245\n",
      "idx: 60, loss: 0.43487367033958435\n",
      "idx: 70, loss: 0.264676570892334\n",
      "idx: 80, loss: 0.22459474205970764\n",
      "idx: 90, loss: 0.15815022587776184\n",
      "idx: 100, loss: 0.2873542308807373\n",
      "Epoch 0. LR: 0.01. Loss: 0.1330 Accuracy 0.8593\n",
      "idx: 0, loss: 0.24276630580425262\n",
      "idx: 10, loss: 0.24393387138843536\n",
      "idx: 20, loss: 0.3756752610206604\n",
      "idx: 30, loss: 0.3193536102771759\n",
      "idx: 40, loss: 0.3344559371471405\n",
      "idx: 50, loss: 0.330405592918396\n",
      "idx: 60, loss: 0.43191859126091003\n",
      "idx: 70, loss: 0.26239141821861267\n",
      "idx: 80, loss: 0.22193747758865356\n",
      "idx: 90, loss: 0.15845946967601776\n",
      "idx: 100, loss: 0.28454288840293884\n",
      "idx: 0, loss: 0.24410191178321838\n",
      "idx: 10, loss: 0.23901551961898804\n",
      "idx: 20, loss: 0.37692299485206604\n",
      "idx: 30, loss: 0.3162826597690582\n",
      "idx: 40, loss: 0.335923433303833\n",
      "idx: 50, loss: 0.3278593420982361\n",
      "idx: 60, loss: 0.4309014678001404\n",
      "idx: 70, loss: 0.25823095440864563\n",
      "idx: 80, loss: 0.21869505941867828\n",
      "idx: 90, loss: 0.15860289335250854\n",
      "idx: 100, loss: 0.2797527015209198\n",
      "idx: 0, loss: 0.24320313334465027\n",
      "idx: 10, loss: 0.23718468844890594\n",
      "idx: 20, loss: 0.37799420952796936\n",
      "idx: 30, loss: 0.31442347168922424\n",
      "idx: 40, loss: 0.3365580141544342\n",
      "idx: 50, loss: 0.3247341513633728\n",
      "idx: 60, loss: 0.4289148151874542\n",
      "idx: 70, loss: 0.25657233595848083\n",
      "idx: 80, loss: 0.21799176931381226\n",
      "idx: 90, loss: 0.15801122784614563\n",
      "idx: 100, loss: 0.2779389023780823\n",
      "idx: 0, loss: 0.24276643991470337\n",
      "idx: 10, loss: 0.23494140803813934\n",
      "idx: 20, loss: 0.3775912821292877\n",
      "idx: 30, loss: 0.3135013282299042\n",
      "idx: 40, loss: 0.33692723512649536\n",
      "idx: 50, loss: 0.3223181962966919\n",
      "idx: 60, loss: 0.42665421962738037\n",
      "idx: 70, loss: 0.2542741298675537\n",
      "idx: 80, loss: 0.21639294922351837\n",
      "idx: 90, loss: 0.15779949724674225\n",
      "idx: 100, loss: 0.2751254737377167\n",
      "Epoch 4. LR: 0.01. Loss: 0.1227 Accuracy 0.8561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:368: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.4289846122264862\n",
      "idx: 10, loss: 0.3740875720977783\n",
      "idx: 20, loss: 0.15936830639839172\n",
      "idx: 30, loss: 0.37657225131988525\n",
      "idx: 40, loss: 0.3776155710220337\n",
      "idx: 50, loss: 0.4178871214389801\n",
      "idx: 60, loss: 0.25362950563430786\n",
      "idx: 70, loss: 0.3689560294151306\n",
      "idx: 80, loss: 0.18768800795078278\n",
      "idx: 90, loss: 0.37067127227783203\n",
      "idx: 100, loss: 0.40362921357154846\n",
      "Epoch 0. LR: 0.01. Loss: 0.2407 Accuracy 0.8711\n",
      "idx: 0, loss: 0.4371291995048523\n",
      "idx: 10, loss: 0.37007078528404236\n",
      "idx: 20, loss: 0.15521498024463654\n",
      "idx: 30, loss: 0.3740788698196411\n",
      "idx: 40, loss: 0.37245792150497437\n",
      "idx: 50, loss: 0.4144226908683777\n",
      "idx: 60, loss: 0.25183019042015076\n",
      "idx: 70, loss: 0.36283841729164124\n",
      "idx: 80, loss: 0.18593142926692963\n",
      "idx: 90, loss: 0.36662566661834717\n",
      "idx: 100, loss: 0.40221717953681946\n",
      "idx: 0, loss: 0.43392157554626465\n",
      "idx: 10, loss: 0.3678009510040283\n",
      "idx: 20, loss: 0.153159037232399\n",
      "idx: 30, loss: 0.37132924795150757\n",
      "idx: 40, loss: 0.3687030076980591\n",
      "idx: 50, loss: 0.41098615527153015\n",
      "idx: 60, loss: 0.24945497512817383\n",
      "idx: 70, loss: 0.36089253425598145\n",
      "idx: 80, loss: 0.1851438730955124\n",
      "idx: 90, loss: 0.3646731972694397\n",
      "idx: 100, loss: 0.40068620443344116\n",
      "idx: 0, loss: 0.4317772686481476\n",
      "idx: 10, loss: 0.366282194852829\n",
      "idx: 20, loss: 0.15096022188663483\n",
      "idx: 30, loss: 0.3688815236091614\n",
      "idx: 40, loss: 0.3655369281768799\n",
      "idx: 50, loss: 0.4073704481124878\n",
      "idx: 60, loss: 0.2485714703798294\n",
      "idx: 70, loss: 0.35878485441207886\n",
      "idx: 80, loss: 0.18483798205852509\n",
      "idx: 90, loss: 0.3633788526058197\n",
      "idx: 100, loss: 0.39863869547843933\n",
      "idx: 0, loss: 0.42910560965538025\n",
      "idx: 10, loss: 0.36372110247612\n",
      "idx: 20, loss: 0.15020069479942322\n",
      "idx: 30, loss: 0.3670734763145447\n",
      "idx: 40, loss: 0.3629140555858612\n",
      "idx: 50, loss: 0.40341922640800476\n",
      "idx: 60, loss: 0.24859091639518738\n",
      "idx: 70, loss: 0.3579692840576172\n",
      "idx: 80, loss: 0.18471726775169373\n",
      "idx: 90, loss: 0.36204642057418823\n",
      "idx: 100, loss: 0.3956715166568756\n",
      "Epoch 4. LR: 0.01. Loss: 0.2114 Accuracy 0.8688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:368: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.2935173809528351\n",
      "idx: 10, loss: 0.38612768054008484\n",
      "idx: 20, loss: 0.5050463080406189\n",
      "idx: 30, loss: 0.3487663269042969\n",
      "idx: 40, loss: 0.3090837597846985\n",
      "idx: 50, loss: 0.4731132388114929\n",
      "idx: 60, loss: 0.4021618664264679\n",
      "idx: 70, loss: 0.3188999593257904\n",
      "idx: 80, loss: 0.30193865299224854\n",
      "idx: 90, loss: 0.3075811266899109\n",
      "idx: 100, loss: 0.35883769392967224\n",
      "idx: 110, loss: 0.26550695300102234\n",
      "idx: 120, loss: 0.540932834148407\n",
      "Epoch 0. LR: 0.01. Loss: 0.3445 Accuracy 0.8595\n",
      "idx: 0, loss: 0.29684337973594666\n",
      "idx: 10, loss: 0.3898363709449768\n",
      "idx: 20, loss: 0.5005451440811157\n",
      "idx: 30, loss: 0.33442625403404236\n",
      "idx: 40, loss: 0.3073117136955261\n",
      "idx: 50, loss: 0.46722549200057983\n",
      "idx: 60, loss: 0.4047456383705139\n",
      "idx: 70, loss: 0.31152108311653137\n",
      "idx: 80, loss: 0.29163649678230286\n",
      "idx: 90, loss: 0.2996607720851898\n",
      "idx: 100, loss: 0.35323941707611084\n",
      "idx: 110, loss: 0.2627159059047699\n",
      "idx: 120, loss: 0.5383138656616211\n",
      "idx: 0, loss: 0.29395726323127747\n",
      "idx: 10, loss: 0.3900972306728363\n",
      "idx: 20, loss: 0.49966520071029663\n",
      "idx: 30, loss: 0.32728976011276245\n",
      "idx: 40, loss: 0.3066674470901489\n",
      "idx: 50, loss: 0.46136271953582764\n",
      "idx: 60, loss: 0.4036690890789032\n",
      "idx: 70, loss: 0.3073020875453949\n",
      "idx: 80, loss: 0.2846471071243286\n",
      "idx: 90, loss: 0.29457375407218933\n",
      "idx: 100, loss: 0.34914839267730713\n",
      "idx: 110, loss: 0.2617405354976654\n",
      "idx: 120, loss: 0.535784125328064\n",
      "idx: 0, loss: 0.29372933506965637\n",
      "idx: 10, loss: 0.3893584609031677\n",
      "idx: 20, loss: 0.4977935254573822\n",
      "idx: 30, loss: 0.3241688907146454\n",
      "idx: 40, loss: 0.3078773617744446\n",
      "idx: 50, loss: 0.4541797637939453\n",
      "idx: 60, loss: 0.40248581767082214\n",
      "idx: 70, loss: 0.3031841218471527\n",
      "idx: 80, loss: 0.27998942136764526\n",
      "idx: 90, loss: 0.29190951585769653\n",
      "idx: 100, loss: 0.34545233845710754\n",
      "idx: 110, loss: 0.2609899342060089\n",
      "idx: 120, loss: 0.532926082611084\n",
      "idx: 0, loss: 0.29098397493362427\n",
      "idx: 10, loss: 0.3877539336681366\n",
      "idx: 20, loss: 0.49724826216697693\n",
      "idx: 30, loss: 0.32016441226005554\n",
      "idx: 40, loss: 0.30697283148765564\n",
      "idx: 50, loss: 0.4501270353794098\n",
      "idx: 60, loss: 0.4023720324039459\n",
      "idx: 70, loss: 0.29924118518829346\n",
      "idx: 80, loss: 0.2757086157798767\n",
      "idx: 90, loss: 0.28804007172584534\n",
      "idx: 100, loss: 0.3431645631790161\n",
      "idx: 110, loss: 0.26071885228157043\n",
      "idx: 120, loss: 0.5305437445640564\n",
      "Epoch 4. LR: 0.01. Loss: 0.3458 Accuracy 0.8582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:368: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.17748525738716125\n",
      "idx: 10, loss: 0.2775939106941223\n",
      "idx: 20, loss: 0.3730621337890625\n",
      "idx: 30, loss: 0.3119337558746338\n",
      "idx: 40, loss: 0.17766794562339783\n",
      "idx: 50, loss: 0.2389228492975235\n",
      "idx: 60, loss: 0.34059247374534607\n",
      "idx: 70, loss: 0.23709024488925934\n",
      "idx: 80, loss: 0.2082555890083313\n",
      "idx: 90, loss: 0.43267005681991577\n",
      "idx: 100, loss: 0.22875286638736725\n",
      "idx: 110, loss: 0.31747835874557495\n",
      "idx: 120, loss: 0.37363773584365845\n",
      "idx: 130, loss: 0.30891361832618713\n",
      "Epoch 0. LR: 0.01. Loss: 0.3570 Accuracy 0.8716\n",
      "idx: 0, loss: 0.17553715407848358\n",
      "idx: 10, loss: 0.27597564458847046\n",
      "idx: 20, loss: 0.3694426119327545\n",
      "idx: 30, loss: 0.29997044801712036\n",
      "idx: 40, loss: 0.17878557741641998\n",
      "idx: 50, loss: 0.23581235110759735\n",
      "idx: 60, loss: 0.33801883459091187\n",
      "idx: 70, loss: 0.22964948415756226\n",
      "idx: 80, loss: 0.20629999041557312\n",
      "idx: 90, loss: 0.4244235157966614\n",
      "idx: 100, loss: 0.2281085103750229\n",
      "idx: 110, loss: 0.31601545214653015\n",
      "idx: 120, loss: 0.37655818462371826\n",
      "idx: 130, loss: 0.3068538308143616\n",
      "idx: 0, loss: 0.17442822456359863\n",
      "idx: 10, loss: 0.2698936462402344\n",
      "idx: 20, loss: 0.363005667924881\n",
      "idx: 30, loss: 0.29162925481796265\n",
      "idx: 40, loss: 0.17789751291275024\n",
      "idx: 50, loss: 0.23306716978549957\n",
      "idx: 60, loss: 0.33657631278038025\n",
      "idx: 70, loss: 0.2229401022195816\n",
      "idx: 80, loss: 0.2051481157541275\n",
      "idx: 90, loss: 0.41902822256088257\n",
      "idx: 100, loss: 0.22736497223377228\n",
      "idx: 110, loss: 0.3149994909763336\n",
      "idx: 120, loss: 0.3755810856819153\n",
      "idx: 130, loss: 0.3020656108856201\n",
      "idx: 0, loss: 0.17337028682231903\n",
      "idx: 10, loss: 0.2656095027923584\n",
      "idx: 20, loss: 0.3595985174179077\n",
      "idx: 30, loss: 0.28566107153892517\n",
      "idx: 40, loss: 0.17876571416854858\n",
      "idx: 50, loss: 0.2319505661725998\n",
      "idx: 60, loss: 0.3337528705596924\n",
      "idx: 70, loss: 0.21846812963485718\n",
      "idx: 80, loss: 0.20801681280136108\n",
      "idx: 90, loss: 0.41443225741386414\n",
      "idx: 100, loss: 0.2253170907497406\n",
      "idx: 110, loss: 0.31342563033103943\n",
      "idx: 120, loss: 0.3744118809700012\n",
      "idx: 130, loss: 0.2976378798484802\n",
      "idx: 0, loss: 0.17365485429763794\n",
      "idx: 10, loss: 0.26011040806770325\n",
      "idx: 20, loss: 0.3546450734138489\n",
      "idx: 30, loss: 0.28033316135406494\n",
      "idx: 40, loss: 0.1792551577091217\n",
      "idx: 50, loss: 0.22984938323497772\n",
      "idx: 60, loss: 0.3320240378379822\n",
      "idx: 70, loss: 0.21390415728092194\n",
      "idx: 80, loss: 0.20868752896785736\n",
      "idx: 90, loss: 0.40876057744026184\n",
      "idx: 100, loss: 0.22400124371051788\n",
      "idx: 110, loss: 0.311208575963974\n",
      "idx: 120, loss: 0.36809390783309937\n",
      "idx: 130, loss: 0.293258935213089\n",
      "Epoch 4. LR: 0.01. Loss: 0.3226 Accuracy 0.8699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:368: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.20520420372486115\n",
      "idx: 10, loss: 0.3032267689704895\n",
      "idx: 20, loss: 0.32029280066490173\n",
      "idx: 30, loss: 0.2814669907093048\n",
      "idx: 40, loss: 0.3362447917461395\n",
      "idx: 50, loss: 0.181362122297287\n",
      "idx: 60, loss: 0.2893568277359009\n",
      "idx: 70, loss: 0.4359720051288605\n",
      "idx: 80, loss: 0.2114362269639969\n",
      "idx: 90, loss: 0.18845097720623016\n",
      "idx: 100, loss: 0.208543062210083\n",
      "idx: 110, loss: 0.14356693625450134\n",
      "idx: 120, loss: 0.166649729013443\n",
      "idx: 130, loss: 0.31547215580940247\n",
      "idx: 140, loss: 0.2918722927570343\n",
      "idx: 150, loss: 0.3049277067184448\n",
      "Epoch 0. LR: 0.01. Loss: 0.1465 Accuracy 0.8722\n",
      "idx: 0, loss: 0.20019538700580597\n",
      "idx: 10, loss: 0.3019161522388458\n",
      "idx: 20, loss: 0.32245421409606934\n",
      "idx: 30, loss: 0.2769036889076233\n",
      "idx: 40, loss: 0.3266076147556305\n",
      "idx: 50, loss: 0.1766679584980011\n",
      "idx: 60, loss: 0.28515878319740295\n",
      "idx: 70, loss: 0.4282435178756714\n",
      "idx: 80, loss: 0.20953625440597534\n",
      "idx: 90, loss: 0.18551094830036163\n",
      "idx: 100, loss: 0.20545807480812073\n",
      "idx: 110, loss: 0.14248204231262207\n",
      "idx: 120, loss: 0.16200578212738037\n",
      "idx: 130, loss: 0.30750685930252075\n",
      "idx: 140, loss: 0.29182857275009155\n",
      "idx: 150, loss: 0.3020021915435791\n",
      "idx: 0, loss: 0.1978897899389267\n",
      "idx: 10, loss: 0.30080798268318176\n",
      "idx: 20, loss: 0.3208180367946625\n",
      "idx: 30, loss: 0.2743123173713684\n",
      "idx: 40, loss: 0.3197323977947235\n",
      "idx: 50, loss: 0.17328909039497375\n",
      "idx: 60, loss: 0.2811111807823181\n",
      "idx: 70, loss: 0.42241594195365906\n",
      "idx: 80, loss: 0.2098521590232849\n",
      "idx: 90, loss: 0.18345516920089722\n",
      "idx: 100, loss: 0.20287644863128662\n",
      "idx: 110, loss: 0.13944624364376068\n",
      "idx: 120, loss: 0.15819115936756134\n",
      "idx: 130, loss: 0.30078059434890747\n",
      "idx: 140, loss: 0.2916170060634613\n",
      "idx: 150, loss: 0.3020174205303192\n",
      "idx: 0, loss: 0.19543780386447906\n",
      "idx: 10, loss: 0.298799991607666\n",
      "idx: 20, loss: 0.31847479939460754\n",
      "idx: 30, loss: 0.271891713142395\n",
      "idx: 40, loss: 0.316240131855011\n",
      "idx: 50, loss: 0.17015676200389862\n",
      "idx: 60, loss: 0.2786751389503479\n",
      "idx: 70, loss: 0.4160175323486328\n",
      "idx: 80, loss: 0.20967723429203033\n",
      "idx: 90, loss: 0.1813558042049408\n",
      "idx: 100, loss: 0.2004942148923874\n",
      "idx: 110, loss: 0.13725614547729492\n",
      "idx: 120, loss: 0.15504835546016693\n",
      "idx: 130, loss: 0.2964029312133789\n",
      "idx: 140, loss: 0.2901451587677002\n",
      "idx: 150, loss: 0.2991434931755066\n",
      "idx: 0, loss: 0.19449862837791443\n",
      "idx: 10, loss: 0.29807013273239136\n",
      "idx: 20, loss: 0.31611359119415283\n",
      "idx: 30, loss: 0.2691969871520996\n",
      "idx: 40, loss: 0.3132142722606659\n",
      "idx: 50, loss: 0.1672816425561905\n",
      "idx: 60, loss: 0.27593716979026794\n",
      "idx: 70, loss: 0.4127032160758972\n",
      "idx: 80, loss: 0.20966535806655884\n",
      "idx: 90, loss: 0.17977002263069153\n",
      "idx: 100, loss: 0.19993017613887787\n",
      "idx: 110, loss: 0.13590259850025177\n",
      "idx: 120, loss: 0.1520387828350067\n",
      "idx: 130, loss: 0.2923630475997925\n",
      "idx: 140, loss: 0.2889818251132965\n",
      "idx: 150, loss: 0.2984806001186371\n",
      "Epoch 4. LR: 0.01. Loss: 0.1384 Accuracy 0.8732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:368: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "idx: 0, loss: 0.24165837466716766\n",
      "idx: 10, loss: 0.31247735023498535\n",
      "idx: 20, loss: 0.2571004033088684\n",
      "idx: 30, loss: 0.2529761791229248\n",
      "idx: 40, loss: 0.27224457263946533\n",
      "idx: 50, loss: 0.39233314990997314\n",
      "idx: 60, loss: 0.21055825054645538\n",
      "idx: 70, loss: 0.28550073504447937\n",
      "idx: 80, loss: 0.22746971249580383\n",
      "idx: 90, loss: 0.27262890338897705\n",
      "idx: 100, loss: 0.30201300978660583\n",
      "idx: 110, loss: 0.16758868098258972\n",
      "idx: 120, loss: 0.21530507504940033\n",
      "idx: 130, loss: 0.23229630291461945\n",
      "idx: 140, loss: 0.2900463044643402\n",
      "idx: 150, loss: 0.5091477036476135\n",
      "idx: 160, loss: 0.3635203540325165\n",
      "Epoch 0. LR: 0.01. Loss: 0.2789 Accuracy 0.8698\n",
      "idx: 0, loss: 0.23113638162612915\n",
      "idx: 10, loss: 0.3110418915748596\n",
      "idx: 20, loss: 0.25866228342056274\n",
      "idx: 30, loss: 0.25173884630203247\n",
      "idx: 40, loss: 0.27542275190353394\n",
      "idx: 50, loss: 0.38753873109817505\n",
      "idx: 60, loss: 0.20886445045471191\n",
      "idx: 70, loss: 0.28134527802467346\n",
      "idx: 80, loss: 0.22228673100471497\n",
      "idx: 90, loss: 0.2720916271209717\n",
      "idx: 100, loss: 0.30078449845314026\n",
      "idx: 110, loss: 0.16191774606704712\n",
      "idx: 120, loss: 0.20934727787971497\n",
      "idx: 130, loss: 0.22673851251602173\n",
      "idx: 140, loss: 0.2894132435321808\n",
      "idx: 150, loss: 0.499560683965683\n",
      "idx: 160, loss: 0.35960713028907776\n",
      "idx: 0, loss: 0.2264062613248825\n",
      "idx: 10, loss: 0.30896422266960144\n",
      "idx: 20, loss: 0.25451362133026123\n",
      "idx: 30, loss: 0.2497401088476181\n",
      "idx: 40, loss: 0.27736786007881165\n",
      "idx: 50, loss: 0.38433024287223816\n",
      "idx: 60, loss: 0.20649205148220062\n",
      "idx: 70, loss: 0.2790903151035309\n",
      "idx: 80, loss: 0.21940606832504272\n",
      "idx: 90, loss: 0.27094197273254395\n",
      "idx: 100, loss: 0.2997418940067291\n",
      "idx: 110, loss: 0.16000398993492126\n",
      "idx: 120, loss: 0.20339663326740265\n",
      "idx: 130, loss: 0.2217760533094406\n",
      "idx: 140, loss: 0.28674545884132385\n",
      "idx: 150, loss: 0.49360939860343933\n",
      "idx: 160, loss: 0.3541363775730133\n",
      "idx: 0, loss: 0.22377225756645203\n",
      "idx: 10, loss: 0.3062833547592163\n",
      "idx: 20, loss: 0.25260424613952637\n",
      "idx: 30, loss: 0.24879644811153412\n",
      "idx: 40, loss: 0.27716657519340515\n",
      "idx: 50, loss: 0.38086408376693726\n",
      "idx: 60, loss: 0.2054339051246643\n",
      "idx: 70, loss: 0.27737268805503845\n",
      "idx: 80, loss: 0.21748195588588715\n",
      "idx: 90, loss: 0.2704126238822937\n",
      "idx: 100, loss: 0.2994222939014435\n",
      "idx: 110, loss: 0.15877360105514526\n",
      "idx: 120, loss: 0.19845141470432281\n",
      "idx: 130, loss: 0.21831485629081726\n",
      "idx: 140, loss: 0.2853657901287079\n",
      "idx: 150, loss: 0.48831069469451904\n",
      "idx: 160, loss: 0.34882089495658875\n",
      "idx: 0, loss: 0.22026550769805908\n",
      "idx: 10, loss: 0.30472567677497864\n",
      "idx: 20, loss: 0.24963369965553284\n",
      "idx: 30, loss: 0.24750497937202454\n",
      "idx: 40, loss: 0.2772122621536255\n",
      "idx: 50, loss: 0.3781629800796509\n",
      "idx: 60, loss: 0.20316971838474274\n",
      "idx: 70, loss: 0.27566224336624146\n",
      "idx: 80, loss: 0.21455661952495575\n",
      "idx: 90, loss: 0.26848748326301575\n",
      "idx: 100, loss: 0.2969200015068054\n",
      "idx: 110, loss: 0.15758992731571198\n",
      "idx: 120, loss: 0.1946595013141632\n",
      "idx: 130, loss: 0.21533483266830444\n",
      "idx: 140, loss: 0.2834285795688629\n",
      "idx: 150, loss: 0.48339366912841797\n",
      "idx: 160, loss: 0.3447344899177551\n",
      "Epoch 4. LR: 0.01. Loss: 0.2573 Accuracy 0.8697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py:368: FutureWarning: If 'random_state' is not supplied, the current default is to use 0 as a fixed seed. This will change to  None in version 1.2 leading to non-deterministic results that better reflect nature of the randomized_svd solver. If you want to silence this warning, set 'random_state' to an integer seed or to None explicitly depending if you want your code to be deterministic or not.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for i in range(n_clients):\n",
    "    lr_init = 1e-2\n",
    "    wd = 0.0\n",
    "    epochs=5\n",
    "    title_i = \"parametrized_preclient_\" + title + str(i)\n",
    "    new_title_i = \"swag_\" + title_i\n",
    "    \n",
    "    swag_model_i = clients[i]\n",
    "    loader_i = client_loaders[i]\n",
    "    model = model_cfg.base(*model_cfg.args, **model_cfg.kwargs)\n",
    "\n",
    "    model.load_state_dict(torch.load(\"ckpts/\" + title_i + \".pt\"))\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=lr_init, weight_decay=wd)\n",
    "    \n",
    "    #test_loader is only included to display accuracy\n",
    "    train(model, loader_i, test_loader, optimizer, criterion, lr_init, epochs, title=new_title_i, print_freq=5, \n",
    "          swag=True, swag_model=swag_model_i, swag_start=1, swag_freq=2, swag_lr=1e-2)\n",
    "    all_probs = model_averaging(swag_model_i, model=model_cfg.base(*model_cfg.args, **model_cfg.kwargs), loader=test_loader)\n",
    "    probs.append(all_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mu_s, Sigma_s = np.vstack([np.array(swag_model._get_mean_and_variance()[0]) for swag_model in clients]), np.vstack([np.array(swag_model._get_mean_and_variance()[1]) for swag_model in clients])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sigma_server = np.reciprocal(np.sum(np.reciprocal(Sigma_s), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mu_server = np.multiply(Sigma_server, np.sum(np.multiply(Mu_s, np.reciprocal(Sigma_s)), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 33.76it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87.57"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model_cfg.base(*model_cfg.args, **model_cfg.kwargs)\n",
    "set_weights(model, torch.tensor(Mu_server))\n",
    "accuracy_model(model, test_loader, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "swag_model = SWAG(model_cfg.base, subspace_type=\"pca\", *model_cfg.args, **model_cfg.kwargs, \n",
    "                  subspace_kwargs={\"max_rank\": 2, \"pca_rank\": 2})\n",
    "swag_model.mean = torch.tensor(Mu_server, dtype=torch.float32)\n",
    "swag_model.sq_mean = torch.tensor(Sigma_server, dtype=torch.float32) + swag_model.mean ** 2\n",
    "swag_model.cov_factor = torch.eye(swag_model.mean.shape[0], dtype=torch.float32) * swag_model.sq_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([85.49])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swag_all_probs = model_averaging(swag_model, model, test_loader, S=10)\n",
    "ytest = np.array(test_loader.dataset.targets)\n",
    "acc_swag = accuracy_all_probs(swag_all_probs, ytest)\n",
    "accuracies['swag'] = acc_swag\n",
    "acc_swag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 34.85it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 32.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu 0: 86.47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 33.39it/s]\n",
      " 15%|                                                                                       | 6/40 [00:00<00:01, 28.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu 1: 87.36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 33.70it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 32.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu 2: 85.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 33.59it/s]\n",
      "  8%|                                                                                               | 3/40 [00:00<00:01, 28.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu 3: 86.71\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 34.16it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:00, 36.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu 4: 85.66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 36.03it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 34.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu 5: 86.92\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 35.15it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:00, 36.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu 6: 85.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 32.69it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 34.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu 7: 87.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 31.61it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:00, 39.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu 8: 87.26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 34.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mu 9: 86.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = model_cfg.base(*model_cfg.args, **model_cfg.kwargs)\n",
    "for i in range(10):\n",
    "    set_weights(model, torch.tensor(Mu_s[i]))\n",
    "    print(f\"Mu {i}:\" , accuracy_model(model, test_loader, 'cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 33.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87.48"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mu_server = np.average(Mu_s, weights=[len(client_loader.dataset) for client_loader in client_loaders.values()], axis=0)\n",
    "model = model_cfg.base(*model_cfg.args, **model_cfg.kwargs)\n",
    "set_weights(model, torch.tensor(new_mu_server))\n",
    "accuracy_model(model, test_loader, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 33.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87.6"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_mu_server = np.mean(Mu_s, axis=0)\n",
    "model = model_cfg.base(*model_cfg.args, **model_cfg.kwargs)\n",
    "set_weights(model, torch.tensor(new_mu_server))\n",
    "accuracy_model(model, test_loader, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([87.49])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_probs = np.average(probs, weights=[len(client_loader.dataset) for client_loader in client_loaders.values()], axis=0)\n",
    "ytest = np.array(test_loader.dataset.targets)\n",
    "accuracy_all_probs(all_probs, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([87.58])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_probs = np.mean(probs, axis=0)\n",
    "ytest = np.array(test_loader.dataset.targets)\n",
    "accuracy_all_probs(all_probs, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 33.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "87.56"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_model(general_model, test_loader, 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [00:08, 21.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 43.8%, Mean loss = 1.637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 20.80it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:00, 36.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 1, Accuracy = 52.83%, Loss = 316.867\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 35.68it/s]\n",
      "2it [00:00, 17.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 1, Test accuracy: 77.99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [00:07, 21.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 81.8%, Mean loss = 0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:10, 21.62it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 30.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 2, Accuracy = 82.41%, Loss = 112.677\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 34.02it/s]\n",
      "3it [00:00, 21.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 2, Test accuracy: 84.33\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [00:07, 20.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 85.5%, Mean loss = 0.397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:10, 21.39it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:00, 37.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 3, Accuracy = 85.56%, Loss = 92.588\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 31.98it/s]\n",
      "3it [00:00, 20.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 3, Test accuracy: 85.49\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [00:08, 18.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 86.5%, Mean loss = 0.368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 20.24it/s]\n",
      "  8%|                                                                                               | 3/40 [00:00<00:01, 27.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 4, Accuracy = 86.42%, Loss = 86.658\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 29.56it/s]\n",
      "2it [00:00, 13.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 4, Test accuracy: 85.29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [00:08, 21.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 87.1%, Mean loss = 0.354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 20.38it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 30.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 5, Accuracy = 87.08%, Loss = 83.141\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 34.25it/s]\n",
      "2it [00:00, 18.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 5, Test accuracy: 85.84\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [00:08, 20.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 87.5%, Mean loss = 0.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 20.31it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 32.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 6, Accuracy = 87.45%, Loss = 80.310\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 33.45it/s]\n",
      "3it [00:00, 23.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 6, Test accuracy: 86.92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [00:07, 21.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 87.9%, Mean loss = 0.330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:10, 21.94it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 32.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 7, Accuracy = 87.88%, Loss = 77.670\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 33.20it/s]\n",
      "3it [00:00, 21.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 7, Test accuracy: 86.16\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [00:08, 19.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.2%, Mean loss = 0.324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 20.40it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 35.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 8, Accuracy = 88.07%, Loss = 76.505\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 31.81it/s]\n",
      "3it [00:00, 22.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 8, Test accuracy: 86.53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [00:07, 20.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.3%, Mean loss = 0.317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 21.18it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 31.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 9, Accuracy = 88.24%, Loss = 75.243\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 32.69it/s]\n",
      "3it [00:00, 23.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 9, Test accuracy: 87.22\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [00:08, 20.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.6%, Mean loss = 0.315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 20.00it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 34.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 10, Accuracy = 88.51%, Loss = 74.178\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 32.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 10, Test accuracy: 87.15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sgld = Sgld(model_cfg.base(*model_cfg.args, **model_cfg.kwargs))\n",
    "sgld_path = \"./ckpts/sgld_\" + title + \".pt\"\n",
    "state_dict, save_dict = sgld.run(train_loader, test_loader, 10, params_optimizer={'lr' : 1e-2}, weight_decay=0.0, t_burn_in=5, path_save_samples=sgld_path)\n",
    "sgld_all_probs = np.array(sgld_tools.predictions(test_loader, model, path=sgld_path, device='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [00:08, 20.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 89.8%, Mean loss = 0.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 20.42it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 32.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 1, Accuracy = 89.64%, Loss = 67.033\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 31.91it/s]\n",
      "2it [00:00, 19.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 1, Test accuracy: 87.55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [00:08, 21.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.6%, Mean loss = 0.312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 20.37it/s]\n",
      "  8%|                                                                                               | 3/40 [00:00<00:01, 29.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 2, Accuracy = 88.60%, Loss = 73.367\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 32.77it/s]\n",
      "3it [00:00, 22.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 2, Test accuracy: 87.1\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [00:08, 19.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.7%, Mean loss = 0.307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 19.67it/s]\n",
      "  8%|                                                                                               | 3/40 [00:00<00:01, 26.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 3, Accuracy = 88.66%, Loss = 72.461\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 30.78it/s]\n",
      "3it [00:00, 20.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 3, Test accuracy: 87.5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [00:08, 20.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.8%, Mean loss = 0.306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 20.59it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:00, 36.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 4, Accuracy = 88.81%, Loss = 72.038\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 34.46it/s]\n",
      "2it [00:00, 19.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 4, Test accuracy: 87.62\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "167it [00:07, 21.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 88.9%, Mean loss = 0.301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:10, 21.41it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:00, 36.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 5, Accuracy = 88.93%, Loss = 71.079\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 34.52it/s]\n",
      "2it [00:00, 18.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 5, Test accuracy: 87.53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [00:08, 19.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 89.0%, Mean loss = 0.300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 20.37it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 31.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 6, Accuracy = 88.96%, Loss = 71.096\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 32.74it/s]\n",
      "3it [00:00, 20.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 6, Test accuracy: 87.6\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [00:08, 20.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 89.1%, Mean loss = 0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 20.42it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:00, 36.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 7, Accuracy = 89.08%, Loss = 70.200\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 33.51it/s]\n",
      "2it [00:00, 16.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 7, Test accuracy: 87.27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "166it [00:08, 19.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 89.1%, Mean loss = 0.298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:11, 19.72it/s]\n",
      "  5%|                                                                                                 | 2/40 [00:00<00:02, 18.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 8, Accuracy = 89.02%, Loss = 70.286\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 31.02it/s]\n",
      "2it [00:00, 19.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 8, Test accuracy: 86.67\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "169it [00:08, 18.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 89.2%, Mean loss = 0.297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:12, 18.86it/s]\n",
      " 10%|                                                                                            | 4/40 [00:00<00:01, 29.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 9, Accuracy = 89.14%, Loss = 69.903\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 29.89it/s]\n",
      "2it [00:00, 17.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 9, Test accuracy: 85.14\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168it [00:08, 19.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 89.3%, Mean loss = 0.294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "235it [00:12, 19.41it/s]\n",
      "  8%|                                                                                               | 3/40 [00:00<00:01, 25.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train --- Epoch 10, Accuracy = 89.20%, Loss = 69.498\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 40/40 [00:01<00:00, 29.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Test --- Epoch: 10, Test accuracy: 86.67\n",
      "\n"
     ]
    }
   ],
   "source": [
    "psgld = Sgld(model_cfg.base(*model_cfg.args, **model_cfg.kwargs))\n",
    "psgld_path = \"./ckpts/psgld_\" + title + \".pt\"\n",
    "pstate_dict, psave_dict = sgld.run(train_loader, test_loader, 10, params_optimizer={'lr' : 1e-2, 'precondition_decay_rate' : 0.95}, weight_decay=0.0, t_burn_in=5, path_save_samples=psgld_path)\n",
    "psgld_all_probs = np.array(sgld_tools.predictions(test_loader, model, path=psgld_path, device='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE = 0.06916936769865004\n",
      "BS = 0.318355854931942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mehdi\\Desktop\\master\\codes\\uncertainties_tools.py:150: RuntimeWarning: Mean of empty slice.\n",
      "  score += np.array([acc[it] - prob_preds[prob_preds >= tau].mean() for it, tau in enumerate(tau_list)])\n",
      "C:\\Users\\mehdi\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECE = 0.04163926838636397\n",
      "BS = 0.18988567365767292\n",
      "ECE = 0.02725438820719721\n",
      "BS = 0.19480501939363096\n"
     ]
    }
   ],
   "source": [
    "save_calibration_scores(swag_all_probs, ytest, title=\"swag\")\n",
    "save_calibration_scores(sgld_all_probs, ytest, title=\"SGLD\")\n",
    "save_calibration_scores(psgld_all_probs, ytest, title=\"pSGLD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nll(all_probs, ytest):\n",
    "    log_it = - np.log(np.take_along_axis(all_probs, np.expand_dims(ytest, axis=1), axis=1)).squeeze()\n",
    "    nll = log_it.mean()\n",
    "    return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4690384132299483"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nll(swag_all_probs, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39080384"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nll(sgld_all_probs, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3930291"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_nll(psgld_all_probs, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={\"figure.dpi\":600, 'savefig.dpi':600})\n",
    "sns.set_style(\"darkgrid\")\n",
    "path_figures = path + \"/figures\"\n",
    "tau_list = np.linspace(0, 1, num=100)\n",
    "for name, all_probs in [('swag', swag_all_probs), ('sgld', sgld_all_probs), ('psgld', psgld_all_probs)]:\n",
    "  acc_conf = accuracy_confidence(all_probs, ytest, tau_list, num_bins = 20)\n",
    "  plt.plot(tau_list, acc_conf, label=name)\n",
    "plt.xlabel(r\"$\\tau$\", fontsize=18)\n",
    "plt.ylabel(r\"accuracy - confidence | confidence $\\geq \\tau$\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.savefig(path_figures + '/acc_conf-' + title + '.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "for name, all_probs in [('swag', swag_all_probs), ('sgld', sgld_all_probs), ('psgld', psgld_all_probs)]:\n",
    "  cal_curve = calibration_curve(all_probs, ytest, num_bins = 20)\n",
    "  plt.plot(cal_curve[1], cal_curve[0] - cal_curve[1], label=name)\n",
    "plt.xlabel(\"confidence\", fontsize=16)\n",
    "plt.ylabel(\"accuracy - confidence\", fontsize=12)\n",
    "plt.legend()\n",
    "plt.savefig(path_figures + '/cal_curve-' + title + '.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
